iter <- iter + 1
print(iter)
prevTheta <- theta
## make sure all theta updated simultaneously
theta <- theta - alpha / nrow(X) *
as.vector(t(1 / (1 + exp(-X %*% theta)) - y) %*% X)
# otherwise return a matrix
J[iter] <- -1 / nrow(X) * (t(y) %*% log(1 / (1 + exp(-X %*% theta))) +
(1 - t(y)) %*% log(1 - 1 / (1 + exp(-X %*% theta))))
#
#         # increase or decrease learning rate based on changes in cost function
#         if (iter > 1 && J[iter] < J[iter - 1]) {
#             alpha <- 1 * alpha
#         } else {
#             alpha <- 1 * alpha
#         }
# terminate if not work well
if (iter > 1e3) {
stop('Too many iterations. Try larger alpha')
}
}
cost <- J[!J == 0]
plot(cost)
return(list(theta = theta, cost = cost))
}
logReg(df, 100)
logReg <- function(trainingData, alpha = 1) {
# Args:
#   traingData: including y, all numerical. y is the last column.
#   alpha: default learning rate is 1
# Returns: a list include
#   $theta: the final theta value
#   $cost: the cost function at each iteration
#
# construct the X matrix including the dummy variable with all ones
# normaliztion
X <- apply(trainingData[1:ncol(trainingData) - 1], 2,
function(x) (x - mean(x)) / sd(x))
## add dummy to x
dummy <- data.frame(x0 = rep(1, nrow(trainingData)))
X <- as.matrix(cbind(dummy, X))
## the response
y <- trainingData[, ncol(trainingData)]
## gradient descent
prevTheta <- rep(Inf, ncol(X))
theta <- rep(1, ncol(X))
iter <- 0 # monitor how many iterations
J <- rep(0, 1000)
while (sum(abs(theta - prevTheta)) > 1e-9) {
# what is the best criteria
iter <- iter + 1
print(iter)
prevTheta <- theta
## make sure all theta updated simultaneously
theta <- theta - alpha / nrow(X) *
as.vector(t(1 / (1 + exp(-X %*% theta)) - y) %*% X)
# otherwise return a matrix
J[iter] <- -1 / nrow(X) * (t(y) %*% log(1 / (1 + exp(-X %*% theta))) +
(1 - t(y)) %*% log(1 - 1 / (1 + exp(-X %*% theta))))
#
#         # increase or decrease learning rate based on changes in cost function
#         if (iter > 1 && J[iter] < J[iter - 1]) {
#             alpha <- 1 * alpha
#         } else {
#             alpha <- 1 * alpha
#         }
# terminate if not work well
if (iter > 1e3) {
stop('Too many iterations. Try larger alpha')
}
}
cost <- J[!J == 0]
plot(cost)
return(list(theta = theta, cost = cost))
}
logReg(df, 100)
logReg <- function(trainingData, alpha = 1) {
# Args:
#   traingData: including y, all numerical. y is the last column.
#   alpha: default learning rate is 1
# Returns: a list include
#   $theta: the final theta value
#   $cost: the cost function at each iteration
#
# construct the X matrix including the dummy variable with all ones
# normaliztion
X <- apply(trainingData[1:ncol(trainingData) - 1], 2,
function(x) (x - mean(x)) / sd(x))
## add dummy to x
dummy <- data.frame(x0 = rep(1, nrow(trainingData)))
X <- as.matrix(cbind(dummy, X))
## the response
y <- trainingData[, ncol(trainingData)]
## gradient descent
prevTheta <- rep(Inf, ncol(X))
theta <- rep(1, ncol(X))
iter <- 0 # monitor how many iterations
J <- rep(0, 1000)
while (sum(abs(theta - prevTheta)) > 1e-9) {
# what is the best criteria
iter <- iter + 1
print(iter)
prevTheta <- theta
# make sure all theta updated simultaneously
# use as.vector(), otherwise return a matrix
theta <- theta - alpha / nrow(X) *
as.vector(t(1 / (1 + exp(-X %*% theta)) - y) %*% X)
# as there are log(), there are NAs when X %*% theta is very large
J[iter] <- -1 / nrow(X) * (t(y) %*% log(1 / (1 + exp(-X %*% theta))) +
(1 - t(y)) %*% log(1 - 1 / (1 + exp(-X %*% theta))))
# increase or decrease learning rate based on changes in cost function
if (iter > 1 && sum(is.na(J[1:iter])) == 0 && J[iter] < J[iter - 1]) {
alpha <- 1 * alpha
} else {
alpha <- 1 * alpha
}
# terminate if not work well
if (iter > 1e3) {
stop('Too many iterations. Try larger alpha')
}
}
cost <- J[!J == 0]
plot(cost)
return(list(theta = theta, cost = cost))
}
logReg(df)
logReg(df, 100)
logReg <- function(trainingData, alpha = 1) {
# Args:
#   traingData: including y, all numerical. y is the last column.
#   alpha: default learning rate is 1
# Returns: a list include
#   $theta: the final theta value
#   $cost: the cost function at each iteration
#
# construct the X matrix including the dummy variable with all ones
# normaliztion
X <- apply(trainingData[1:ncol(trainingData) - 1], 2,
function(x) (x - mean(x)) / sd(x))
## add dummy to x
dummy <- data.frame(x0 = rep(1, nrow(trainingData)))
X <- as.matrix(cbind(dummy, X))
## the response
y <- trainingData[, ncol(trainingData)]
## gradient descent
prevTheta <- rep(Inf, ncol(X))
theta <- rep(1, ncol(X))
iter <- 0 # monitor how many iterations
J <- rep(0, 1000)
while (sum(abs(theta - prevTheta)) > 1e-9) {
# what is the best criteria
iter <- iter + 1
print(iter)
prevTheta <- theta
# make sure all theta updated simultaneously
# use as.vector(), otherwise return a matrix
theta <- theta - alpha / nrow(X) *
as.vector(t(1 / (1 + exp(-X %*% theta)) - y) %*% X)
# as there are log(), there are NAs when X %*% theta is very large
J[iter] <- -1 / nrow(X) * (t(y) %*% log(1 / (1 + exp(-X %*% theta))) +
(1 - t(y)) %*% log(1 - 1 / (1 + exp(-X %*% theta))))
# increase or decrease learning rate based on changes in cost function
if (iter > 1 && sum(is.na(J[1:iter])) == 0 && J[iter] < J[iter - 1]) {
alpha <- 2 * alpha
} else {
alpha <- 0.5 * alpha
}
# terminate if not work well
if (iter > 1e3) {
stop('Too many iterations. Try larger alpha')
}
}
cost <- J[!J == 0]
plot(cost)
return(list(theta = theta, cost = cost))
}
logReg(df)
logReg <- function(trainingData, alpha = 1) {
# Args:
#   traingData: including y, all numerical. y is the last column.
#   alpha: default learning rate is 1
# Returns: a list include
#   $theta: the final theta value
#   $cost: the cost function at each iteration
#
# construct the X matrix including the dummy variable with all ones
# normaliztion
X <- apply(trainingData[1:ncol(trainingData) - 1], 2,
function(x) (x - mean(x)) / sd(x))
## add dummy to x
dummy <- data.frame(x0 = rep(1, nrow(trainingData)))
X <- as.matrix(cbind(dummy, X))
## the response
y <- trainingData[, ncol(trainingData)]
## gradient descent
prevTheta <- rep(Inf, ncol(X))
theta <- rep(1, ncol(X))
iter <- 0 # monitor how many iterations
J <- rep(0, 1000)
while (sum(abs(theta - prevTheta)) > 1e-9) {
# what is the best criteria
iter <- iter + 1
print(iter)
prevTheta <- theta
# make sure all theta updated simultaneously
# use as.vector(), otherwise return a matrix
theta <- theta - alpha / nrow(X) *
as.vector(t(1 / (1 + exp(-X %*% theta)) - y) %*% X)
# as there are log(), there are NAs when X %*% theta is very large
J[iter] <- -1 / nrow(X) * (t(y) %*% log(1 / (1 + exp(-X %*% theta))) +
(1 - t(y)) %*% log(1 - 1 / (1 + exp(-X %*% theta))))
# increase or decrease learning rate based on changes in cost function
if (iter > 1 && sum(is.na(J[1:iter])) == 0 && J[iter] < J[iter - 1]) {
alpha <- 1.2 * alpha
} else {
alpha <- 0.9 * alpha
}
# terminate if not work well
if (iter > 1e3) {
stop('Too many iterations. Try larger alpha')
}
}
cost <- J[!J == 0]
plot(cost)
return(list(theta = theta, cost = cost))
}
logReg(df)
logReg <- function(trainingData, alpha = 1) {
# Args:
#   traingData: including y, all numerical. y is the last column.
#   alpha: default learning rate is 1
# Returns: a list include
#   $theta: the final theta value
#   $cost: the cost function at each iteration
#
# construct the X matrix including the dummy variable with all ones
# normaliztion
X <- apply(trainingData[1:ncol(trainingData) - 1], 2,
function(x) (x - mean(x)) / sd(x))
## add dummy to x
dummy <- data.frame(x0 = rep(1, nrow(trainingData)))
X <- as.matrix(cbind(dummy, X))
## the response
y <- trainingData[, ncol(trainingData)]
## gradient descent
prevTheta <- rep(Inf, ncol(X))
theta <- rep(1, ncol(X))
iter <- 0 # monitor how many iterations
J <- rep(0, 1000)
while (sum(abs(theta - prevTheta)) > 1e-9) {
# what is the best criteria
iter <- iter + 1
print(iter)
prevTheta <- theta
# make sure all theta updated simultaneously
# use as.vector(), otherwise return a matrix
theta <- theta - alpha / nrow(X) *
as.vector(t(1 / (1 + exp(-X %*% theta)) - y) %*% X)
# as there are log(), there are NAs when X %*% theta is very large
J[iter] <- -1 / nrow(X) * (t(y) %*% log(1 / (1 + exp(-X %*% theta))) +
(1 - t(y)) %*% log(1 - 1 / (1 + exp(-X %*% theta))))
# increase or decrease learning rate based on changes in cost function
if (iter > 1 && sum(is.na(J[1:iter])) == 0 && J[iter] < J[iter - 1]) {
alpha <- 1.2 * alpha
} else {
alpha <- 0.8 * alpha
}
# terminate if not work well
if (iter > 1e3) {
stop('Too many iterations. Try larger alpha')
}
}
cost <- J[!J == 0]
plot(cost)
return(list(theta = theta, cost = cost))
}
logReg(df)
logReg <- function(trainingData, alpha = 1) {
# Args:
#   traingData: including y, all numerical. y is the last column.
#   alpha: default learning rate is 1
# Returns: a list include
#   $theta: the final theta value
#   $cost: the cost function at each iteration
#
# construct the X matrix including the dummy variable with all ones
# normaliztion
X <- apply(trainingData[1:ncol(trainingData) - 1], 2,
function(x) (x - mean(x)) / sd(x))
## add dummy to x
dummy <- data.frame(x0 = rep(1, nrow(trainingData)))
X <- as.matrix(cbind(dummy, X))
## the response
y <- trainingData[, ncol(trainingData)]
## gradient descent
prevTheta <- rep(Inf, ncol(X))
theta <- rep(0, ncol(X))
iter <- 0 # monitor how many iterations
J <- rep(0, 1000)
while (sum(abs(theta - prevTheta)) > 1e-9) {
# what is the best criteria
iter <- iter + 1
print(iter)
prevTheta <- theta
# make sure all theta updated simultaneously
# use as.vector(), otherwise return a matrix
theta <- theta - alpha / nrow(X) *
as.vector(t(1 / (1 + exp(-X %*% theta)) - y) %*% X)
# as there are log(), there are NAs when X %*% theta is very large
J[iter] <- -1 / nrow(X) * (t(y) %*% log(1 / (1 + exp(-X %*% theta))) +
(1 - t(y)) %*% log(1 - 1 / (1 + exp(-X %*% theta))))
# increase or decrease learning rate based on changes in cost function
if (iter > 1 && sum(is.na(J[1:iter])) == 0 && J[iter] < J[iter - 1]) {
alpha <- 1.2 * alpha
} else {
alpha <- 0.8 * alpha
}
# terminate if not work well
if (iter > 1e3) {
stop('Too many iterations. Try larger alpha')
}
}
cost <- J[!J == 0]
plot(cost)
return(list(theta = theta, cost = cost))
}
logReg(df)
logReg <- function(trainingData, alpha = 1) {
# Args:
#   traingData: including y, all numerical. y is the last column.
#   alpha: default learning rate is 1
# Returns: a list include
#   $theta: the final theta value
#   $cost: the cost function at each iteration
#
# construct the X matrix including the dummy variable with all ones
# normaliztion
X <- apply(trainingData[1:ncol(trainingData) - 1], 2,
function(x) (x - mean(x)) / sd(x))
## add dummy to x
dummy <- data.frame(x0 = rep(1, nrow(trainingData)))
X <- as.matrix(cbind(dummy, X))
## the response
y <- trainingData[, ncol(trainingData)]
## gradient descent
prevTheta <- rep(Inf, ncol(X))
theta <- rep(0, ncol(X))
iter <- 0 # monitor how many iterations
J <- rep(0, 1000)
while (sum(abs(theta - prevTheta)) > 1e-9) {
# what is the best criteria
iter <- iter + 1
print(iter)
prevTheta <- theta
# make sure all theta updated simultaneously
# use as.vector(), otherwise return a matrix
theta <- theta - alpha / nrow(X) *
as.vector(t(1 / (1 + exp(-X %*% theta)) - y) %*% X)
# as there are log(), there are NAs when X %*% theta is very large
J[iter] <- -1 / nrow(X) * (t(y) %*% log(1 / (1 + exp(-X %*% theta))) +
(1 - t(y)) %*% log(1 - 1 / (1 + exp(-X %*% theta))))
# increase or decrease learning rate based on changes in cost function
# too high steps may cause trouble
if (iter > 1 && sum(is.na(J[1:iter])) == 0 && J[iter] < J[iter - 1]) {
alpha <- 2 * alpha
} else {
alpha <- 0.5 * alpha
}
# terminate if not work well
if (iter > 1e3) {
stop('Too many iterations. Try larger alpha')
}
}
cost <- J[!J == 0]
plot(cost)
return(list(theta = theta, cost = cost))
}
logReg(df)
logReg(df, 100)
logReg(df)
library(ggplot2)
g <- ggplot(df, aes(x1, x2))
g + geom_point(aes(color = y))
g + geom_point(aes(color = factor(y)))
g + geom_point(aes(color = factor(y))) + geom_line(x = c(0, -0.29/4.34), y = c(-0.29/4.71, 0))
g + geom_point(aes(color = factor(y))) + geom_line(aes(x = c(0, -0.29/4.34), y = c(-0.29/4.71, 0)))
glm(df)
aaa <- glm(y ~., df, bionomial)
aaa <- glm(y ~., df, family = binomial)
summary(aaa)
aaa
2 * pt(-9.559, 30)
lmFit <- lm(mpg ~ wt, data = mtcars)
sd(lmFit$residuals)
summary(lmFit$residuals)
sd(lmFit$residuals)
sd(lmFit$residuals) * sqrt(32 / 30)
summary(lmFit)
sd(lmFit$residuals) * sqrt(31 / 30)
mean(lmFit$residuals)
sqrt(sum(lmFit$residuals^2)/31)
sqrt(sum(lmFit$residuals^2)/30)
sum(lmFit$residuals * mtcars$wt)
sum(lmFit$residuals * mtcars$wt)
http://d396qusza40orc.cloudfront.net/statistics/lec_resources/states.csv
pair(mtcars)
pairs(mtcars)
load(url("http://www.openintro.org/stat/data/evals.RData"))
View(evals)
summary(evals)
hist(evals$score)
sum(evals$score < 3)
plot(evals$score ~ evals$bty_avg)
?jitter
plot(evals$score ~ jitter(evals$bty_avg)
)
plot(evals$score ~ evals$bty_avg, alpha = 0.5)
plot(evals$score ~ jitter(evals$bty_avg)
)
m_bty <- lm(score ~ bty_avg, data = evals)
abline(m_bty)
summary(m_bty)
plot(m_bty$residuals)
plot(m_bty$residuals, evals$bty_avg)
hist(m_bty$residuals)
plot(evals$bty_avg ~ evals$bty_f1lower)
cor(evals$bty_avg, evals$bty_f1lower)
plot(evals[,13:19])
m_bty_gen <- lm(score ~ bty_avg + gender, data = evals)
summary(m_bty_gen)
plot(m_bty_gen)
plot(m_bty_gen)
multiLines(m_bty_gen)
m_bty_rank <- lm(score ~ bty_avg + rank, data = evals)
summary(m_bty_rank)
m_full <- lm(score ~ rank + ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
summary(m_full)
m_full <- lm(score ~ rank + ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_profs + cls_credits + bty_avg, data = evals)
summary(m_full)
m1 <- lm(score ~ ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
summary(m1) -> aaa
aaa$adj.r.squared
m2 = lm(score ~ rank + gender + language + age + cls_perc_eval +
cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
summary(m2)$adj.r.squared
# gender
m1 <- lm(score ~ ethnicity + language + age + cls_perc_eval
+ cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
summary(m1)$adj.r.squared
# language
m1 <- lm(score ~ ethnicity + gender + age + cls_perc_eval
+ cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
summary(m1)$adj.r.squared
# age
m1 <- lm(score ~ ethnicity + gender + language + cls_perc_eval
+ cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
summary(m1)$adj.r.squared
# cls_perc_eval
m1 <- lm(score ~ ethnicity + gender + language + age
+ cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
summary(m1)$adj.r.squared
# cls_studet
m1 <- lm(score ~ ethnicity + gender + language + age + cls_perc_eval
+ cls_level + cls_profs + cls_credits + bty_avg, data = evals)
summary(m1)$adj.r.squared
# cls_level
m1 <- lm(score ~ ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_profs + cls_credits + bty_avg, data = evals)
summary(m1)$adj.r.squared
# cls_prof
m1 <- lm(score ~ ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_credits + bty_avg, data = evals)
summary(m1)$adj.r.squared
# cls_credti
m1 <- lm(score ~ ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_profs + bty_avg, data = evals)
summary(m1)$adj.r.squared
# bty_avg
m1 <- lm(score ~ ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_profs + cls_credits, data = evals)
summary(m1)$adj.r.squared
shiny::runApp('Dropbox/shiny_homepage')
setwd("~/Dropbox/shiny_homepage/www")
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
shiny::runApp('~/Dropbox/shiny_homepage')
